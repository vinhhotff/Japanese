/**
 * ============================================
 * C·∫§U H√åNH GI·ªåNG N√ìI - CH·ªàNH ·ªû ƒê√ÇY
 * ============================================
 * 
 * File n√†y ch·ª©a t·∫•t c·∫£ c·∫•u h√¨nh v·ªÅ gi·ªçng n√≥i.
 * ƒê·ªÉ ch·ªânh gi·ªçng n√≥i, h√£y s·ª≠a c√°c gi√° tr·ªã trong DEFAULT_SPEECH_CONFIG b√™n d∆∞·ªõi.
 * 
 * C√ÅCH CH·ªàNH:
 * 1. M·ªü file: src/utils/speech.ts
 * 2. T√¨m d√≤ng: const DEFAULT_SPEECH_CONFIG
 * 3. Thay ƒë·ªïi c√°c gi√° tr·ªã:
 *    - rate: T·ªëc ƒë·ªô n√≥i (0.5 = r·∫•t ch·∫≠m, 1.0 = b√¨nh th∆∞·ªùng, 2.0 = r·∫•t nhanh)
 *    - pitch: Cao ƒë·ªô gi·ªçng (0.5 = tr·∫ßm, 1.0 = b√¨nh th∆∞·ªùng, 2.0 = cao)
 *    - volume: √Çm l∆∞·ª£ng (0.0 = im l·∫∑ng, 1.0 = to nh·∫•t)
 *    - voiceName: T√™n gi·ªçng c·ª• th·ªÉ (xem danh s√°ch b·∫±ng c√°ch ch·∫°y getAvailableVoices())
 * 
 * V√ç D·ª§:
 * - Gi·ªçng ch·∫≠m v√† r√µ: rate: 0.7, pitch: 1.0, volume: 1.0
 * - Gi·ªçng n·ªØ cao: rate: 0.8, pitch: 1.3, volume: 1.0
 * - Gi·ªçng nam tr·∫ßm: rate: 0.8, pitch: 0.8, volume: 1.0
 * 
 * ============================================
 */

// Text-to-Speech utilities

// C·∫•u h√¨nh gi·ªçng n√≥i - B·∫†N C√ì TH·ªÇ CH·ªàNH ·ªû ƒê√ÇY
export interface SpeechConfig {
  lang: string;        // Ng√¥n ng·ªØ: 'ja-JP' (ti·∫øng Nh·∫≠t)
  rate: number;         // T·ªëc ƒë·ªô: 0.1 - 10 (0.7 = ch·∫≠m, 1.0 = b√¨nh th∆∞·ªùng, 1.3 = nhanh)
  pitch: number;       // Cao ƒë·ªô: 0 - 2 (0.5 = th·∫•p, 1.0 = b√¨nh th∆∞·ªùng, 1.5 = cao)
  volume: number;      // √Çm l∆∞·ª£ng: 0 - 1 (0.5 = nh·ªè, 1.0 = to nh·∫•t)
  voiceName?: string;  // T√™n gi·ªçng c·ª• th·ªÉ (ƒë·ªÉ tr·ªëng = t·ª± ƒë·ªông ch·ªçn)
}

// ============================================
// ‚öôÔ∏è C·∫§U H√åNH GI·ªåNG N√ìI - CH·ªàNH ·ªû ƒê√ÇY ‚öôÔ∏è
// ============================================
// 
// Thay ƒë·ªïi c√°c gi√° tr·ªã b√™n d∆∞·ªõi ƒë·ªÉ ƒëi·ªÅu ch·ªânh gi·ªçng n√≥i:
//
const DEFAULT_SPEECH_CONFIG: SpeechConfig = {
  lang: 'ja-JP',           // Ng√¥n ng·ªØ: 'ja-JP' (ti·∫øng Nh·∫≠t)
  
  // T·ªêC ƒê·ªò (rate): 0.1 - 10
  // - 0.5-0.7: R·∫•t ch·∫≠m, d·ªÖ nghe cho ng∆∞·ªùi m·ªõi h·ªçc
  // - 0.8-0.9: Ch·∫≠m v·ª´a ph·∫£i (KHUY·∫æN NGH·ªä)
  // - 1.0: T·ªëc ƒë·ªô b√¨nh th∆∞·ªùng
  // - 1.2-1.5: Nhanh
  rate: 0.75,              // üëà CH·ªàNH S·ªê N√ÄY ƒë·ªÉ thay ƒë·ªïi t·ªëc ƒë·ªô (0.7 = ch·∫≠m, d·ªÖ nghe)
  
  // CAO ƒê·ªò (pitch): 0 - 2
  // - 0.5-0.8: Gi·ªçng tr·∫ßm (nam)
  // - 1.0: B√¨nh th∆∞·ªùng
  // - 1.2-1.5: Gi·ªçng cao (n·ªØ)
  pitch: 1.0,               // üëà CH·ªàNH S·ªê N√ÄY ƒë·ªÉ thay ƒë·ªïi cao ƒë·ªô (1.2 = cao h∆°n, 0.8 = tr·∫ßm h∆°n)
  
  // √ÇM L∆Ø·ª¢NG (volume): 0 - 1
  // - 0.5-0.7: Nh·ªè
  // - 0.8-0.9: V·ª´a
  // - 1.0: To nh·∫•t
  volume: 1.0,              // üëà CH·ªàNH S·ªê N√ÄY ƒë·ªÉ thay ƒë·ªïi √¢m l∆∞·ª£ng (1.0 = to nh·∫•t)
  
  // GI·ªåNG C·ª§ TH·ªÇ (voiceName): 
  // - undefined: T·ª± ƒë·ªông ch·ªçn gi·ªçng ti·∫øng Nh·∫≠t t·ªët nh·∫•t
  // - Ho·∫∑c ƒë·∫∑t t√™n gi·ªçng c·ª• th·ªÉ, v√≠ d·ª•: 'Google Êó•Êú¨Ë™û'
  // ƒê·ªÉ xem danh s√°ch gi·ªçng c√≥ s·∫µn, m·ªü Console tr√¨nh duy·ªát v√† ch·∫°y:
  //   speechSynthesis.getVoices().forEach(v => console.log(v.name, v.lang))
  voiceName: undefined       // üëà ƒê·∫∑t t√™n gi·ªçng c·ª• th·ªÉ n·∫øu mu·ªën (v√≠ d·ª•: 'Google Êó•Êú¨Ë™û')
};

// L·∫•y danh s√°ch gi·ªçng c√≥ s·∫µn
export const getAvailableVoices = (): SpeechSynthesisVoice[] => {
  if ('speechSynthesis' in window) {
    return window.speechSynthesis.getVoices();
  }
  return [];
};

// L·∫•y gi·ªçng ti·∫øng Nh·∫≠t t·ªët nh·∫•t
const getBestJapaneseVoice = (): SpeechSynthesisVoice | null => {
  const voices = getAvailableVoices();
  
  // ∆Øu ti√™n gi·ªçng n·ªØ ti·∫øng Nh·∫≠t
  const femaleJapanese = voices.find(v => 
    v.lang.startsWith('ja') && v.name.toLowerCase().includes('female')
  );
  if (femaleJapanese) return femaleJapanese;
  
  // T√¨m gi·ªçng ti·∫øng Nh·∫≠t b·∫•t k·ª≥
  const japaneseVoice = voices.find(v => v.lang.startsWith('ja'));
  if (japaneseVoice) return japaneseVoice;
  
  return null;
};

// L·∫•y gi·ªçng ti·∫øng Trung t·ªët nh·∫•t
const getBestChineseVoice = (): SpeechSynthesisVoice | null => {
  const voices = getAvailableVoices();
  
  // ∆Øu ti√™n Google Chinese voices
  const googleChinese = voices.find(v => 
    v.lang.startsWith('zh') && v.name.toLowerCase().includes('google')
  );
  if (googleChinese) return googleChinese;
  
  // ∆Øu ti√™n gi·ªçng n·ªØ ti·∫øng Trung
  const femaleChinese = voices.find(v => 
    v.lang.startsWith('zh') && v.name.toLowerCase().includes('female')
  );
  if (femaleChinese) return femaleChinese;
  
  // T√¨m gi·ªçng ti·∫øng Trung Mandarin (zh-CN)
  const mandarinVoice = voices.find(v => v.lang === 'zh-CN');
  if (mandarinVoice) return mandarinVoice;
  
  // T√¨m gi·ªçng ti·∫øng Trung b·∫•t k·ª≥
  const chineseVoice = voices.find(v => v.lang.startsWith('zh'));
  if (chineseVoice) return chineseVoice;
  
  return null;
};

export const speakText = (
  text: string, 
  config: Partial<SpeechConfig> = {}
) => {
  if ('speechSynthesis' in window) {
    // Cancel any ongoing speech
    window.speechSynthesis.cancel();

    // K·∫øt h·ª£p c·∫•u h√¨nh m·∫∑c ƒë·ªãnh v·ªõi c·∫•u h√¨nh t√πy ch·ªânh
    const finalConfig: SpeechConfig = {
      ...DEFAULT_SPEECH_CONFIG,
      ...config
    };

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = finalConfig.lang;
    utterance.rate = finalConfig.rate;
    utterance.pitch = finalConfig.pitch;
    utterance.volume = finalConfig.volume;

    // Ch·ªçn gi·ªçng n·∫øu c√≥
    if (finalConfig.voiceName) {
      const voices = getAvailableVoices();
      const selectedVoice = voices.find(v => v.name === finalConfig.voiceName);
      if (selectedVoice) {
        utterance.voice = selectedVoice;
      }
    } else {
      // T·ª± ƒë·ªông ch·ªçn gi·ªçng t·ªët nh·∫•t d·ª±a tr√™n ng√¥n ng·ªØ
      let bestVoice: SpeechSynthesisVoice | null = null;
      
      if (finalConfig.lang.startsWith('zh')) {
        // Ti·∫øng Trung
        bestVoice = getBestChineseVoice();
      } else if (finalConfig.lang.startsWith('ja')) {
        // Ti·∫øng Nh·∫≠t
        bestVoice = getBestJapaneseVoice();
      }
      
      if (bestVoice) {
        utterance.voice = bestVoice;
      } else {
        console.warn('No suitable voice found for language:', finalConfig.lang);
        
        // Fallback: Th·ª≠ s·ª≠ d·ª•ng gi·ªçng m·∫∑c ƒë·ªãnh c·ªßa h·ªá th·ªëng
        const allVoices = getAvailableVoices();
        if (allVoices.length > 0) {
          utterance.voice = allVoices[0];
        }
      }
    }

    return new Promise<void>((resolve, reject) => {
      utterance.onend = () => resolve();
      utterance.onerror = (error) => {
        console.error('Speech synthesis error:', error);
        // Kh√¥ng reject ƒë·ªÉ tr√°nh crash app, ch·ªâ log l·ªói
        resolve(); // Resolve thay v√¨ reject
      };
      
      try {
        window.speechSynthesis.speak(utterance);
      } catch (error) {
        console.error('Failed to speak:', error);
        resolve(); // Resolve thay v√¨ reject
      }
    });
  } else {
    return Promise.reject(new Error('Speech synthesis not supported'));
  }
};

// H√†m ti·ªán √≠ch ƒë·ªÉ ch·ªânh gi·ªçng d·ªÖ d√†ng h∆°n
export const speakTextWithSettings = (
  text: string,
  options: {
    slow?: boolean;      // true = ch·∫≠m h∆°n (0.7), false = b√¨nh th∆∞·ªùng (0.8)
    highPitch?: boolean; // true = gi·ªçng cao (1.2), false = b√¨nh th∆∞·ªùng (1.0)
    loud?: boolean;      // true = to h∆°n (1.0), false = b√¨nh th∆∞·ªùng (0.9)
  } = {}
) => {
  const config: Partial<SpeechConfig> = {
    rate: options.slow ? 0.7 : 0.8,
    pitch: options.highPitch ? 1.2 : 1.0,
    volume: options.loud ? 1.0 : 0.9,
  };
  return speakText(text, config);
};

export const stopSpeaking = () => {
  if ('speechSynthesis' in window) {
    window.speechSynthesis.cancel();
  }
};

export const isSpeechSynthesisSupported = () => {
  return 'speechSynthesis' in window;
};

// Debug function ƒë·ªÉ ki·ªÉm tra voices c√≥ s·∫µn
export const logAvailableVoices = () => {
  if ('speechSynthesis' in window) {
    const voices = window.speechSynthesis.getVoices();
    console.log('=== Available Voices ===');
    voices.forEach((voice, index) => {
      console.log(`${index + 1}. ${voice.name} (${voice.lang}) - ${voice.localService ? 'Local' : 'Remote'}`);
    });
    
    const japaneseVoices = voices.filter(v => v.lang.startsWith('ja'));
    console.log('=== Japanese Voices ===');
    if (japaneseVoices.length > 0) {
      japaneseVoices.forEach((voice, index) => {
        console.log(`${index + 1}. ${voice.name} (${voice.lang})`);
      });
    } else {
      console.log('No Japanese voices found');
    }
  } else {
    console.log('Speech synthesis not supported');
  }
};

// Function ƒë·ªÉ th·ª≠ ph√°t √¢m v·ªõi fallback
export const speakTextSafely = async (text: string, config: Partial<SpeechConfig> = {}) => {
  try {
    await speakText(text, config);
  } catch (error) {
    console.warn('Speech failed, continuing silently:', error);
    // Kh√¥ng throw error ƒë·ªÉ tr√°nh crash app
  }
};

// Speech Recognition utilities
export interface SpeechRecognitionResult {
  transcript: string;
  confidence: number;
}

export const startSpeechRecognition = (
  lang: string = 'ja-JP',
  onResult: (result: SpeechRecognitionResult) => void,
  onError?: (error: string) => void,
  onEnd?: () => void
): (() => void) => {
  const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
  
  if (!SpeechRecognition) {
    onError?.('Speech recognition not supported in this browser');
    return () => {};
  }

  const recognition = new SpeechRecognition();
  recognition.lang = lang;
  recognition.continuous = false;
  recognition.interimResults = false;
  recognition.maxAlternatives = 1;

  recognition.onresult = (event: any) => {
    const result = event.results[0];
    onResult({
      transcript: result[0].transcript,
      confidence: result[0].confidence
    });
  };

  recognition.onerror = (event: any) => {
    let errorMessage = 'C√≥ l·ªói x·∫£y ra khi nh·∫≠n di·ªán gi·ªçng n√≥i';
    if (event.error === 'no-speech') {
      errorMessage = 'Kh√¥ng ph√°t hi·ªán gi·ªçng n√≥i';
    } else if (event.error === 'audio-capture') {
      errorMessage = 'Kh√¥ng th·ªÉ truy c·∫≠p microphone';
    } else if (event.error === 'not-allowed') {
      errorMessage = 'Quy·ªÅn truy c·∫≠p microphone b·ªã t·ª´ ch·ªëi';
    }
    onError?.(errorMessage);
  };

  recognition.onend = () => {
    onEnd?.();
  };

  recognition.start();

  return () => {
    recognition.stop();
  };
};

export const isSpeechRecognitionSupported = () => {
  return !!(window as any).SpeechRecognition || !!(window as any).webkitSpeechRecognition;
};

// Compare two Japanese texts (simple comparison)
export const compareJapaneseText = (text1: string, text2: string): {
  match: boolean;
  similarity: number;
  differences: string[];
} => {
  // Remove punctuation, spaces and normalize
  const normalize = (text: string) => text.replace(/[„ÄÇ„ÄÅÔºüÔºÅ\s]/g, '').trim();
  
  const normalized1 = normalize(text1);
  const normalized2 = normalize(text2);
  
  // Exact match
  if (normalized1 === normalized2) {
    return { match: true, similarity: 100, differences: [] };
  }
  
  // Check if texts are similar (case-insensitive for romaji)
  const lower1 = normalized1.toLowerCase();
  const lower2 = normalized2.toLowerCase();
  
  if (lower1 === lower2) {
    return { match: true, similarity: 95, differences: [] };
  }
  
  // Calculate similarity using Levenshtein-like algorithm
  // For Japanese, we compare character by character
  const len1 = normalized1.length;
  const len2 = normalized2.length;
  
  if (len1 === 0 && len2 === 0) {
    return { match: true, similarity: 100, differences: [] };
  }
  
  if (len1 === 0 || len2 === 0) {
    return { 
      match: false, 
      similarity: 0, 
      differences: [`K·ª≥ v·ªçng: ${text1}`, `B·∫°n n√≥i: ${text2}`] 
    };
  }
  
  // Calculate character matches
  let matches = 0;
  const minLength = Math.min(len1, len2);
  const maxLength = Math.max(len1, len2);
  
  // Check for exact character matches
  for (let i = 0; i < minLength; i++) {
    if (normalized1[i] === normalized2[i]) {
      matches++;
    }
  }
  
  // If one text contains the other, give partial credit
  if (normalized1.includes(normalized2) || normalized2.includes(normalized1)) {
    const containedLength = Math.min(len1, len2);
    const similarity = (containedLength / maxLength) * 100;
    return {
      match: similarity >= 80,
      similarity: Math.round(similarity),
      differences: similarity < 80 ? [`K·ª≥ v·ªçng: ${text1}`, `B·∫°n n√≥i: ${text2}`] : []
    };
  }
  
  // Calculate similarity based on character matches
  const similarity = maxLength > 0 ? (matches / maxLength) * 100 : 0;
  
  const differences: string[] = [];
  if (similarity < 80) {
    differences.push(`K·ª≥ v·ªçng: ${text1}`);
    differences.push(`B·∫°n n√≥i: ${text2}`);
  }
  
  return { 
    match: similarity >= 80, 
    similarity: Math.round(similarity), 
    differences 
  };
};

